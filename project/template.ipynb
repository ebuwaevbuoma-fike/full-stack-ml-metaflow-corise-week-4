{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Full Stack Machine Learning's Week 4 Project!\n",
    "\n",
    "In the final week, you will return to the workflow you built last week on the [taxi dataset](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Deploy the champion\n",
    "Use what you have learned in the last two weeks to make necessary modifications and to deploy your latest version of the `TaxiFarePrediction` flow to Argo. Use `--branch champion` to denote this deployment as the champion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../flows/cloud/taxi_data_champion.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../flows/cloud/taxi_data_champion.py\n",
    "from metaflow import FlowSpec, step, card, conda_base, current, Parameter, Flow, trigger\n",
    "from metaflow import project, S3\n",
    "from metaflow.cards import Markdown, Table, Image, Artifact\n",
    "\n",
    "# URL = \"https://outerbounds-datasets.s3.us-west-2.amazonaws.com/taxi/latest.parquet\"\n",
    "URL = 's3://outerbounds-datasets/taxi/latest.parquet'\n",
    "\n",
    "DATETIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "@trigger(events=['s3'])\n",
    "@conda_base(libraries={'pandas': '1.4.2', 'pyarrow': '11.0.0', 'numpy': '1.21.2', 'scikit-learn': '1.1.2'})\n",
    "@project(name='taxifare_prediction')\n",
    "class TaxiFarePrediction(FlowSpec):\n",
    "\n",
    "    data_url = Parameter(\"data_url\", default=URL)\n",
    "\n",
    "    def transform_features(self, df):\n",
    "       \n",
    "\n",
    "        obviously_bad_data_filters = [\n",
    "            df.fare_amount > 0,         # fare_amount in US Dollars\n",
    "            df.trip_distance <= 100,    # trip_distance in miles\n",
    "            df.trip_distance > 0,\n",
    "            df.passenger_count <= 5 #most taxis can only sit 4 passengers\n",
    "        ]\n",
    "        for f in obviously_bad_data_filters:\n",
    "            df = df[f]\n",
    "            \n",
    "        return df\n",
    "    @step\n",
    "    def start(self):\n",
    "\n",
    "        import pandas as pd\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        with S3() as s3:\n",
    "            obj = s3.get(URL)\n",
    "            df = pd.read_parquet(obj.path)\n",
    "\n",
    "        self.df = self.transform_features(df)\n",
    "        # self.df = self.transform_features(pd.read_parquet(self.data_url))\n",
    "\n",
    "        # NOTE: we are split into training and validation set in the validation step which uses cross_val_score.\n",
    "        \n",
    "        self.X = self.df[\"trip_distance\"].values.reshape(-1, 1)\n",
    "        self.y = self.df[\"total_amount\"].values\n",
    "        self.next(self.linear_model)\n",
    "    \n",
    "    @step\n",
    "    def linear_model(self):\n",
    "        \"Fit a single variable, linear model to the data.\"\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "\n",
    "        # TODO: Play around with the model if you are feeling it.\n",
    "        self.model = LinearRegression()\n",
    "        self.next(self.validate)\n",
    "\n",
    "    def gather_sibling_flow_run_results(self):\n",
    "\n",
    "        # storage to populate and feed to a Table in a Metaflow card\n",
    "        rows = []\n",
    "\n",
    "        # loop through runs of this flow \n",
    "        for run in Flow(self.__class__.__name__):\n",
    "            if run.id != current.run_id:\n",
    "                if run.successful:\n",
    "                    icon = \"‚úÖ\" \n",
    "                    msg = \"OK\"\n",
    "                    score = str(run.data.scores.mean())\n",
    "                else:\n",
    "                    icon = \"‚ùå\"\n",
    "                    msg = \"Error\"\n",
    "                    score = \"NA\"\n",
    "                    for step in run:\n",
    "                        for task in step:\n",
    "                            if not task.successful:\n",
    "                                msg = task.stderr\n",
    "                row = [Markdown(icon), Artifact(run.id), Artifact(run.created_at.strftime(DATETIME_FORMAT)), Artifact(score), Markdown(msg)]\n",
    "                rows.append(row)\n",
    "            else:\n",
    "                rows.append([Markdown(\"‚úÖ\"), Artifact(run.id), Artifact(run.created_at.strftime(DATETIME_FORMAT)), Artifact(str(self.scores.mean())), Markdown(\"This run...\")])\n",
    "        return rows\n",
    "    \n",
    "    @card(type=\"corise\")\n",
    "    @step\n",
    "    def validate(self):\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        self.scores = cross_val_score(self.model, self.X, self.y, cv=5)\n",
    "        current.card.append(Markdown(\"# Taxi Fare Prediction Results\"))\n",
    "        current.card.append(Table(self.gather_sibling_flow_run_results(), headers=[\"Pass/fail\", \"Run ID\", \"Created At\", \"R^2 score\", \"Stderr\"]))\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        self.model_name = 'champion'\n",
    "        self.model_type = \"regression\"\n",
    "        print(f'Score: {self.scores.mean():.2f}')\n",
    "        print(\"Success!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TaxiFarePrediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.8.6+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mProject: \u001b[0m\u001b[32m\u001b[1mtaxifare_prediction\u001b[0m\u001b[35m\u001b[22m, Branch: \u001b[0m\u001b[32m\u001b[1muser.sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[22mBootstrapping conda environment...(this could take a few minutes)\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:31.226 \u001b[0m\u001b[1mWorkflow starting (run-id 386), see it in the UI at https://ui-pw-2141923211.outerbounds.dev/TaxiFarePrediction/386\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:32.200 \u001b[0m\u001b[32m[386/start/961 (pid 18590)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:43.526 \u001b[0m\u001b[32m[386/start/961 (pid 18590)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:44.477 \u001b[0m\u001b[32m[386/linear_model/962 (pid 18701)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:46.934 \u001b[0m\u001b[32m[386/linear_model/962 (pid 18701)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:47.978 \u001b[0m\u001b[32m[386/validate/963 (pid 18745)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:54.689 \u001b[0m\u001b[32m[386/validate/963 (pid 18745)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:55.642 \u001b[0m\u001b[32m[386/end/964 (pid 18809)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:56.835 \u001b[0m\u001b[32m[386/end/964 (pid 18809)] \u001b[0m\u001b[22mScore: 0.90\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:57.609 \u001b[0m\u001b[32m[386/end/964 (pid 18809)] \u001b[0m\u001b[22mSuccess!\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:57.811 \u001b[0m\u001b[32m[386/end/964 (pid 18809)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:14:57.995 \u001b[0m\u001b[1mDone! See the run in the UI at https://ui-pw-2141923211.outerbounds.dev/TaxiFarePrediction/386\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python ../flows/cloud/taxi_data_champion.py --environment=conda run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.8.6+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mProject: \u001b[0m\u001b[32m\u001b[1mtaxifare_prediction\u001b[0m\u001b[35m\u001b[22m, Branch: \u001b[0m\u001b[32m\u001b[1mprod.champion\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[1mDeploying \u001b[0m\u001b[31m\u001b[1mtaxifareprediction.prod.champion.taxifareprediction\u001b[0m\u001b[1m to Argo Workflows...\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mThe namespace of this production flow is\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    production:mfprj-bl5jeer7xehnsiac-0-hqum\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mTo analyze results of this production flow add this line in your notebooks:\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    namespace(\"production:mfprj-bl5jeer7xehnsiac-0-hqum\")\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mIf you want to authorize other people to deploy new versions of this flow to Argo Workflows, they need to call\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    argo-workflows create --authorize mfprj-bl5jeer7xehnsiac-0-hqum\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mwhen deploying this flow to Argo Workflows for the first time.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mSee \"Organizing Results\" at https://docs.metaflow.org/ for more information about production tokens.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mBootstrapping conda environment...(this could take a few minutes)\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1mWorkflow \u001b[0m\u001b[31m\u001b[1mtaxifareprediction.prod.champion.taxifareprediction\u001b[0m\u001b[1m for flow \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[1m pushed to Argo Workflows successfully.\n",
      "\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22mNote that the flow was deployed with a modified name due to Kubernetes naming conventions\n",
      "on Argo Workflows. The original flow name is stored in the workflow annotation.\n",
      "\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1mWhat will trigger execution of the workflow:\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22m    This workflow triggers automatically when the upstream \u001b[0m\u001b[31m\u001b[1ms3\u001b[0m\u001b[22m event is/are published.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#create workflow\n",
    "! python ../flows/cloud/taxi_data_champion.py --environment=conda --production --branch champion --production argo-workflows create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.8.6+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mProject: \u001b[0m\u001b[32m\u001b[1mtaxifare_prediction\u001b[0m\u001b[35m\u001b[22m, Branch: \u001b[0m\u001b[32m\u001b[1mprod.champion\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[1mWorkflow \u001b[0m\u001b[31m\u001b[1mtaxifareprediction.prod.champion.taxifareprediction\u001b[0m\u001b[1m triggered on Argo Workflows (run-id \u001b[0m\u001b[31m\u001b[1margo-taxifareprediction.prod.champion.taxifareprediction-nnzbz\u001b[0m\u001b[1m).\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[1mSee the run in the UI at https://ui-pw-2141923211.outerbounds.dev/TaxiFarePrediction/argo-taxifareprediction.prod.champion.taxifareprediction-nnzbz\u001b[K\u001b[0m\u001b[1m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#trigger workflow\n",
    "! python ../flows/cloud/taxi_data_champion.py --environment=conda --production --branch champion --production argo-workflows trigger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Build the challenger\n",
    "Develop a second model, by using the same `TaxiFarePrediction` architecture. Then, deploy the flow to Argo as the `--branch challenger`. \n",
    "<br>\n",
    "<br>\n",
    "Hint: Modify the `linear_model` step. \n",
    "<br>\n",
    "Bonus: Write a paragraph summary of how you developed the second model and tested it before deploying the challenger flow. Let us know in Slack what you found challenging about the task? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../flows/cloud/taxi_data_challenger.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../flows/cloud/taxi_data_challenger.py\n",
    "from metaflow import FlowSpec, step, card, conda_base, current, Parameter, Flow, trigger\n",
    "from metaflow import project, S3\n",
    "from metaflow.cards import Markdown, Table, Image, Artifact\n",
    "\n",
    "# URL = \"https://outerbounds-datasets.s3.us-west-2.amazonaws.com/taxi/latest.parquet\"\n",
    "URL = 's3://outerbounds-datasets/taxi/latest.parquet'\n",
    "DATETIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "@trigger(events=['s3'])\n",
    "@conda_base(libraries={'pandas': '1.4.2', 'pyarrow': '11.0.0', 'numpy': '1.21.2', 'scikit-learn': '1.1.2', 'xgboost' : '1.7.4'})\n",
    "@project(name='taxifare_prediction')\n",
    "class TaxiFarePrediction(FlowSpec):\n",
    "\n",
    "    data_url = Parameter(\"data_url\", default=URL)\n",
    "\n",
    "    def transform_features(self, df):\n",
    "        # TODO: \n",
    "        # Try to complete tasks 2 and 3 with this function doing nothing like it currently is.\n",
    "        # Understand what is happening.\n",
    "        # Revisit task 1 and think about what might go in this function.\n",
    "\n",
    "        obviously_bad_data_filters = [\n",
    "            df.fare_amount > 0,         # fare_amount in US Dollars\n",
    "            df.trip_distance <= 100,    # trip_distance in miles\n",
    "            df.trip_distance > 0,\n",
    "            df.passenger_count <= 5 #most taxis can only sit 4 passengers\n",
    "        ]\n",
    "        for f in obviously_bad_data_filters:\n",
    "            df = df[f]\n",
    "\n",
    "        return df\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "\n",
    "        import pandas as pd\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        with S3() as s3:\n",
    "            obj = s3.get(URL)\n",
    "            df = pd.read_parquet(obj.path)\n",
    "\n",
    "        self.df = self.transform_features(df)\n",
    "        # self.df = self.transform_features(pd.read_parquet(self.data_url))\n",
    "\n",
    "        # NOTE: we are split into training and validation set in the validation step which uses cross_val_score.\n",
    "      \n",
    "        self.X = self.df[\"trip_distance\"].values.reshape(-1, 1)\n",
    "        self.y = self.df[\"total_amount\"].values\n",
    "        self.next(self.xgboost_model)\n",
    "    \n",
    "    @step\n",
    "    def xgboost_model(self):\n",
    "        \"Fit an XGBoost regressor\"\n",
    "        from xgboost import XGBRegressor\n",
    "        self.model = XGBRegressor()\n",
    "        self.next(self.validate)\n",
    "\n",
    "    def gather_sibling_flow_run_results(self):\n",
    "\n",
    "        # storage to populate and feed to a Table in a Metaflow card\n",
    "        rows = []\n",
    "\n",
    "        # loop through runs of this flow \n",
    "        for run in Flow(self.__class__.__name__):\n",
    "            if run.id != current.run_id:\n",
    "                if run.successful:\n",
    "                    icon = \"‚úÖ\" \n",
    "                    msg = \"OK\"\n",
    "                    score = str(run.data.scores.mean())\n",
    "                else:\n",
    "                    icon = \"‚ùå\"\n",
    "                    msg = \"Error\"\n",
    "                    score = \"NA\"\n",
    "                    for step in run:\n",
    "                        for task in step:\n",
    "                            if not task.successful:\n",
    "                                msg = task.stderr\n",
    "                row = [Markdown(icon), Artifact(run.id), Artifact(run.created_at.strftime(DATETIME_FORMAT)), Artifact(score), Markdown(msg)]\n",
    "                rows.append(row)\n",
    "            else:\n",
    "                rows.append([Markdown(\"‚úÖ\"), Artifact(run.id), Artifact(run.created_at.strftime(DATETIME_FORMAT)), Artifact(str(self.scores.mean())), Markdown(\"This run...\")])\n",
    "        return rows\n",
    "\n",
    "    @card(type=\"corise\")\n",
    "    @step\n",
    "    def validate(self):\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "\n",
    "        self.scores = cross_val_score(self.model, self.X, self.y, cv=5)\n",
    "        \n",
    "        current.card.append(Markdown(\"# Taxi Fare Prediction Results\"))\n",
    "        current.card.append(Table(self.gather_sibling_flow_run_results(), headers=[\"Pass/fail\", \"Run ID\", \"Created At\", \"R^2 score\", \"Stderr\"]))\n",
    "        self.next(self.end)\n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        self.model_name = 'challenger'\n",
    "        self.model_type = \"xgboost\"\n",
    "        print(f'{self.model_name} score: {self.scores.mean():.2f}')\n",
    "        print(\"Success!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TaxiFarePrediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.8.6+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mProject: \u001b[0m\u001b[32m\u001b[1mtaxifare_prediction\u001b[0m\u001b[35m\u001b[22m, Branch: \u001b[0m\u001b[32m\u001b[1muser.sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[22mBootstrapping conda environment...(this could take a few minutes)\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[35m2023-05-24 05:25:32.319 \u001b[0m\u001b[1mWorkflow starting (run-id 388), see it in the UI at https://ui-pw-2141923211.outerbounds.dev/TaxiFarePrediction/388\u001b[0m\n",
      "\u001b[35m2023-05-24 05:25:33.275 \u001b[0m\u001b[32m[388/start/974 (pid 19248)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:25:40.012 \u001b[0m\u001b[32m[388/start/974 (pid 19248)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:25:40.946 \u001b[0m\u001b[32m[388/xgboost_model/975 (pid 19344)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:25:43.739 \u001b[0m\u001b[32m[388/xgboost_model/975 (pid 19344)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:25:44.614 \u001b[0m\u001b[32m[388/validate/976 (pid 19396)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:27:11.461 \u001b[0m\u001b[32m[388/validate/976 (pid 19396)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:27:12.395 \u001b[0m\u001b[32m[388/end/977 (pid 19459)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:27:13.928 \u001b[0m\u001b[32m[388/end/977 (pid 19459)] \u001b[0m\u001b[22mchallenger score: 0.91\u001b[0m\n",
      "\u001b[35m2023-05-24 05:27:14.587 \u001b[0m\u001b[32m[388/end/977 (pid 19459)] \u001b[0m\u001b[22mSuccess!\u001b[0m\n",
      "\u001b[35m2023-05-24 05:27:14.776 \u001b[0m\u001b[32m[388/end/977 (pid 19459)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2023-05-24 05:27:14.920 \u001b[0m\u001b[1mDone! See the run in the UI at https://ui-pw-2141923211.outerbounds.dev/TaxiFarePrediction/388\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python ../flows/cloud/taxi_data_challenger.py --environment=conda run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.8.6+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mProject: \u001b[0m\u001b[32m\u001b[1mtaxifare_prediction\u001b[0m\u001b[35m\u001b[22m, Branch: \u001b[0m\u001b[32m\u001b[1mprod.challenger\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[1mDeploying \u001b[0m\u001b[31m\u001b[1mtaxifareprediction.prod.challenger.taxifareprediction\u001b[0m\u001b[1m to Argo Workflows...\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22mIt seems this is the first time you are deploying \u001b[0m\u001b[31m\u001b[1mtaxifareprediction.prod.challenger.taxifareprediction\u001b[0m\u001b[22m to Argo Workflows.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mA new production token generated.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mThe namespace of this production flow is\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    production:mfprj-a2atl4ukaehxrfie-0-uate\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mTo analyze results of this production flow add this line in your notebooks:\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    namespace(\"production:mfprj-a2atl4ukaehxrfie-0-uate\")\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mIf you want to authorize other people to deploy new versions of this flow to Argo Workflows, they need to call\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    argo-workflows create --authorize mfprj-a2atl4ukaehxrfie-0-uate\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mwhen deploying this flow to Argo Workflows for the first time.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mSee \"Organizing Results\" at https://docs.metaflow.org/ for more information about production tokens.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mBootstrapping conda environment...(this could take a few minutes)\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1mWorkflow \u001b[0m\u001b[31m\u001b[1mtaxifareprediction.prod.challenger.taxifareprediction\u001b[0m\u001b[1m for flow \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[1m pushed to Argo Workflows successfully.\n",
      "\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22mNote that the flow was deployed with a modified name due to Kubernetes naming conventions\n",
      "on Argo Workflows. The original flow name is stored in the workflow annotation.\n",
      "\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1mWhat will trigger execution of the workflow:\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22m    This workflow triggers automatically when the upstream \u001b[0m\u001b[31m\u001b[1ms3\u001b[0m\u001b[22m event is/are published.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python ../flows/cloud/taxi_data_challenger.py --environment=conda --production --branch challenger --production argo-workflows create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.8.6+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mProject: \u001b[0m\u001b[32m\u001b[1mtaxifare_prediction\u001b[0m\u001b[35m\u001b[22m, Branch: \u001b[0m\u001b[32m\u001b[1mprod.challenger\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[1mWorkflow \u001b[0m\u001b[31m\u001b[1mtaxifareprediction.prod.challenger.taxifareprediction\u001b[0m\u001b[1m triggered on Argo Workflows (run-id \u001b[0m\u001b[31m\u001b[1margo-taxifareprediction.prod.challenger.taxifareprediction-gn9wk\u001b[0m\u001b[1m).\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[1mSee the run in the UI at https://ui-pw-2141923211.outerbounds.dev/TaxiFarePrediction/argo-taxifareprediction.prod.challenger.taxifareprediction-gn9wk\u001b[K\u001b[0m\u001b[1m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#trigger workflow\n",
    "! python ../flows/cloud/taxi_data_challenger.py --environment=conda --production --branch challenger --production argo-workflows trigger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Analyze the results\n",
    "Return to this notebook, and read in the results of the challenger and champion flow using the Metaflow Client API.\n",
    "<br><br>\n",
    "\n",
    "#### Questions\n",
    "- Does your model perform better on the metrics you selected? \n",
    "- Think about your day job, how would you go about assessing whether to roll forward the production \"champion\" to your new model? \n",
    "    - What gives you confidence one model is better than another?\n",
    "    - What kinds of information do you need to monitor to get buy-in from stakeholders that model A is preferable to model B?  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would need to monitor data quality issues to get buy-in for the challenger model. Currently, the data is hardcoded to exclude values using the obviously_bad_filters function. With domain expertise, this could be customized even further, with a cascading sequence for handling missing completely at random vs missing not at random values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Flow('Template_Flow'),\n",
       " Flow('TFlow1'),\n",
       " Flow('RF_Flow'),\n",
       " Flow('BSTFlow'),\n",
       " Flow('NNFlow'),\n",
       " Flow('BaselineNLPFlow'),\n",
       " Flow('Branch_Flow'),\n",
       " Flow('TFlow2'),\n",
       " Flow('TFlow4'),\n",
       " Flow('TFlow5'),\n",
       " Flow('BaselineChallenge'),\n",
       " Flow('BaselineChallenge_1'),\n",
       " Flow('RF_Flow_cloud'),\n",
       " Flow('Branch_Flow_Cloud'),\n",
       " Flow('Branch_Cloud_Step'),\n",
       " Flow('Branch_Cloud_Flow'),\n",
       " Flow('DivideByZeroFlow'),\n",
       " Flow('RetryFlow'),\n",
       " Flow('TimeoutFlow'),\n",
       " Flow('CatchDivideByZeroFlow'),\n",
       " Flow('TaxiFarePrediction'),\n",
       " Flow('TitanicSurvivalPredictor')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metaflow import namespace, Metaflow\n",
    "\n",
    "namespace('user:sandbox')\n",
    "Metaflow().flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Flow, namespace\n",
    "\n",
    "# these values are unique to your deployment!\n",
    "CHAMPION_MODEL_NAMESPACE = 'production:mfprj-bl5jeer7xehnsiac-0-hqum' # \"production:mfprj-xsfdb3gtsiboqyrd-0-vqsy\"\n",
    "CHALLENGER_MODEL_NAMESPACE = 'production:mfprj-a2atl4ukaehxrfie-0-uate' # \"production:mfprj-cfyzlfzievjlmsf4-0-tbgz\"\n",
    "\n",
    "best_score = -1; winner = None; winner_namespace = None\n",
    "for n in [CHAMPION_MODEL_NAMESPACE, CHALLENGER_MODEL_NAMESPACE]:\n",
    "    namespace(n)\n",
    "    run = Flow('TaxiFarePrediction').latest_successful_run\n",
    "    acc_score = max(run.data.scores)\n",
    "    if acc_score > best_score:\n",
    "        best_score = acc_score\n",
    "        winner = run.data.model_name\n",
    "        winner_namespace = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winner is the challenger model, with accuracy of 90.78%. You can find the model in the flow deployed to the production:mfprj-a2atl4ukaehxrfie-0-uate namespace.\n"
     ]
    }
   ],
   "source": [
    "print(\"The winner is the {} model, with accuracy of {}%. You can find the model in the flow deployed to the {} namespace.\".format(winner, round(100*best_score, 2), winner_namespace))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONGRATULATIONS! üéâ‚ú®üçæ\n",
    "If you made it this far, you have completed the Full Stack Machine Learning Corise course. \n",
    "We are so glad that you chose to learn with us, and hope to see you again in future courses. Stay tuned for more content and come join us in [Slack](http://slack.outerbounds.co/) to keep learning about Metaflow!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Full Stack ML Corise",
   "language": "python",
   "name": "full-stack-metaflow-corise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
